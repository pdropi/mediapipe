// src/video-upload.ts

import {
Â  PoseLandmarker,
Â  FilesetResolver,
Â  DrawingUtils,
Â  PoseLandmarkerResult,
Â  NormalizedLandmark,
} from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

// Importa o novo utilitÃ¡rio. Vite resolverÃ¡ a extensÃ£o .ts.
import { analyzeErgonomics } from "./ergonomics-utils.ts"; 

const demosSection = document.getElementById("demos");
let poseLandmarker: PoseLandmarker = undefined;
let angleDisplay: HTMLParagraphElement; // Elemento para exibir o Ã¢ngulo

const createPoseLandmarker = async () => {
Â  const vision = await FilesetResolver.forVisionTasks(
Â  Â  "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
Â  );
Â  poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
Â  Â  baseOptions: {
Â  Â  Â  modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,
Â  Â  Â  delegate: "GPU",
Â  Â  },
Â  Â  runningMode: "VIDEO",
Â  Â  numPoses: 2,
Â  });
Â  demosSection.classList.remove("invisible");
Â  console.log("âœ… PoseLandmarker loaded for video upload");
Â Â 
Â  // ðŸ†• Cria e anexa o elemento de exibiÃ§Ã£o do Ã¢ngulo (Painel)
Â  angleDisplay = document.createElement('p');
Â  angleDisplay.id = 'angleDisplay';
Â  angleDisplay.style.cssText = 'position: absolute; top: 10px; right: 10px; color: white; background: rgba(0,0,0,0.7); padding: 5px 10px; border-radius: 5px; z-index: 10; font-weight: bold; font-family: monospace;';
Â  const videoContainer = document.getElementById("uploadedVideoContainer");
Â  if (videoContainer) videoContainer.appendChild(angleDisplay);

Â  setupVideoUpload();
};
createPoseLandmarker();

function setupVideoUpload() {
Â  const videoUpload = document.getElementById("videoUpload") as HTMLInputElement;
Â  const uploadedVideo = document.getElementById("uploadedVideo") as HTMLVideoElement;
Â  const uploadCanvas = document.getElementById("uploadCanvas") as HTMLCanvasElement;
Â  const uploadCtx = uploadCanvas.getContext("2d")!;
Â  const uploadDrawingUtils = new DrawingUtils(uploadCtx);

Â  // Canvas temporÃ¡rio para processamento
Â  const tempCanvas = document.createElement('canvas');
Â  const tempCtx = tempCanvas.getContext('2d')!;
Â Â 
Â  // DimensÃµes mÃ¡ximas compatÃ­veis
Â  const MAX_WIDTH = 1280;
Â  const MAX_HEIGHT = 720;

Â  let uploadVideoPredicting = false;
Â  let lastUploadVideoTime = -1;

Â  videoUpload.addEventListener("change", handleVideoUpload);

Â  async function handleVideoUpload(event: Event) {
Â  Â  const input = event.target as HTMLInputElement;
Â  Â  if (!input.files || input.files.length === 0) return;

Â  Â  const file = input.files[0];
Â  Â  const fileURL = URL.createObjectURL(file);
Â  Â  uploadedVideo.src = fileURL;
Â  Â  console.log("ðŸ“‚ File loaded:", file.name);

Â  Â  // Reset canvas
Â  Â  uploadCtx.clearRect(0, 0, uploadCanvas.width, uploadCanvas.height);
Â  Â  uploadVideoPredicting = false;
Â  Â  if (angleDisplay) angleDisplay.textContent = 'Aguardando vÃ­deo...';

Â  Â  uploadedVideo.onloadedmetadata = () => {
Â  Â  Â  console.log("ðŸŽžï¸ Video metadata loaded");
Â  Â  Â  console.log("Original video dimensions:", uploadedVideo.videoWidth, uploadedVideo.videoHeight);
Â  Â  Â Â 
Â  Â  Â  // Calcula dimensÃµes para processamento
Â  Â  Â  let processedWidth = uploadedVideo.videoWidth;
Â  Â  Â  let processedHeight = uploadedVideo.videoHeight;
Â  Â  Â Â 
Â  Â  Â  if (processedWidth > MAX_WIDTH || processedHeight > MAX_HEIGHT) {
Â  Â  Â  Â  const ratio = Math.min(MAX_WIDTH / processedWidth, MAX_HEIGHT / processedHeight);
Â  Â  Â  Â  processedWidth = Math.floor(processedWidth * ratio);
Â  Â  Â  Â  processedHeight = Math.floor(processedHeight * ratio);
Â  Â  Â  Â  console.log(`ðŸ“ Resizing for processing: ${processedWidth}x${processedHeight}`);
Â  Â  Â  }
Â  Â  Â Â 
Â  Â  Â  // Configura canvas temporÃ¡rio
Â  Â  Â  tempCanvas.width = processedWidth;
Â  Â  Â  tempCanvas.height = processedHeight;
Â  Â  Â Â 
Â  Â  Â  // Configura canvas de exibiÃ§Ã£o mantendo proporÃ§Ã£o original
Â  Â  Â  const displayRatio = Math.min(MAX_WIDTH / uploadedVideo.videoWidth, MAX_HEIGHT / uploadedVideo.videoHeight);
Â  Â  Â  const displayWidth = Math.floor(uploadedVideo.videoWidth * displayRatio);
Â  Â  Â  const displayHeight = Math.floor(uploadedVideo.videoHeight * displayRatio);
Â  Â  Â Â 
Â  Â  Â  uploadCanvas.width = displayWidth;
Â  Â  Â  uploadCanvas.height = displayHeight;
Â  Â  Â Â 
Â  Â  Â  console.log("Processing canvas:", tempCanvas.width, tempCanvas.height);
Â  Â  Â  console.log("Display canvas:", uploadCanvas.width, uploadCanvas.height);

Â  Â  Â  // Fatores de escala (globais para acesso fÃ¡cil)
Â  Â  Â  (window as any).scaleX = uploadCanvas.width / tempCanvas.width;
Â  Â  Â  (window as any).scaleY = uploadCanvas.height / tempCanvas.height;
Â  Â  };

Â  Â  uploadedVideo.onplay = () => {
Â  Â  Â  console.log("â–¶ï¸ Video started. Starting prediction loop...");
Â  Â  Â  if (!uploadVideoPredicting) {
Â  Â  Â  Â  uploadVideoPredicting = true;
Â  Â  Â  Â  lastUploadVideoTime = -1;
Â  Â  Â  Â  predictUploadedVideo();
Â  Â  Â  }
Â  Â  };

Â  Â  uploadedVideo.onpause = () => {
Â  Â  Â  console.log("â¸ï¸ Video paused");
Â  Â  Â  uploadVideoPredicting = false;
Â  Â  };

Â  Â  uploadedVideo.onended = () => {
Â  Â  Â  console.log("â¹ï¸ Video ended");
Â  Â  Â  uploadVideoPredicting = false;
Â  Â  Â  uploadCtx.clearRect(0, 0, uploadCanvas.width, uploadCanvas.height);
Â  Â  Â  if (angleDisplay) angleDisplay.textContent = 'AnÃ¡lise concluÃ­da.';
Â  Â  };

Â  Â  uploadedVideo.onerror = (err) => {
Â  Â  Â  console.error("âŒ Video error:", err);
Â  Â  Â  uploadVideoPredicting = false;
Â  Â  };
Â  }

Â  async function predictUploadedVideo() {
Â  Â  if (!poseLandmarker || !uploadVideoPredicting || uploadedVideo.ended || uploadedVideo.paused) {
Â  Â  Â  uploadVideoPredicting = false;
Â  Â  Â  return;
Â  Â  }

Â  Â  const now = performance.now();
Â  Â Â 
Â  Â  if (uploadedVideo.currentTime !== lastUploadVideoTime) {
Â  Â  Â  lastUploadVideoTime = uploadedVideo.currentTime;

Â  Â  Â  try {
Â  Â  Â  Â  // Processa no canvas temporÃ¡rio
Â  Â  Â  Â  tempCtx.clearRect(0, 0, tempCanvas.width, tempCanvas.height);
Â  Â  Â  Â  tempCtx.drawImage(uploadedVideo, 0, 0, tempCanvas.width, tempCanvas.height);
Â  Â  Â  Â Â 
Â  Â  Â  Â  poseLandmarker.detectForVideo(tempCanvas, now, (result: PoseLandmarkerResult) => {
Â  Â  Â  Â  Â  uploadCtx.clearRect(0, 0, uploadCanvas.width, uploadCanvas.height);
Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  if (result.landmarks && result.landmarks.length > 0) {
Â  Â  Â  Â  Â  Â  // Assumimos a primeira pose como a principal
Â  Â  Â  Â  Â  Â  const landmarks: NormalizedLandmark[] = result.landmarks[0];
            
            // ðŸ†• 1. CÃ¡lculo do Ã¢ngulo cervical
            const { neckAngle } = analyzeErgonomics(landmarks);

            // ðŸ†• 2. ExibiÃ§Ã£o do Ã¢ngulo (Apenas para a primeira pose)
            if (angleDisplay) {
                if (neckAngle !== null) {
                    const formattedAngle = neckAngle.toFixed(2);
                    // O Ã¢ngulo Ã© o desvio em relaÃ§Ã£o ao vertical. 0Â° Ã© ERETO.
                    angleDisplay.textContent = `Ã‚ngulo Cervical: ${formattedAngle}Â°`;

                    // Feedback ErgonÃ´mico: FlexÃ£o excessiva (e.g., desvio > 10 graus)
                    const MAX_SAFE_DEVIATION = 15; // Exemplo: 15 graus de desvio
                    
                    if (Math.abs(neckAngle) > MAX_SAFE_DEVIATION) {
                        angleDisplay.style.color = 'red';
                    } else if (Math.abs(neckAngle) > 8) {
                        angleDisplay.style.color = 'yellow';
                    } else {
                        angleDisplay.style.color = 'lime';
                    }
                } else {
                    angleDisplay.textContent = 'Ã‚ngulo Cervical: NÃ£o detectado';
                    angleDisplay.style.color = 'white';
                }
            }


Â  Â  Â  Â  Â  Â  // 3. Desenho dos Landmarks e ConexÃµes
Â  Â  Â  Â  Â  Â  Â  // Escala os landmarks
Â  Â  Â  Â  Â  Â  Â  const scaledLandmarks = landmarks.map(landmark => ({
Â  Â  Â  Â  Â  Â  Â  Â  ...landmark,
Â  Â  Â  Â  Â  Â  Â  Â  // Usa o fator de escala definido no onloadedmetadata
Â  Â  Â  Â  Â  Â  Â  Â  x: landmark.x * (window as any).scaleX,
Â  Â  Â  Â  Â  Â  Â  Â  y: landmark.y * (window as any).scaleY
Â  Â  Â  Â  Â  Â  Â  }));
Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  uploadDrawingUtils.drawLandmarks(scaledLandmarks, {
Â  Â  Â  Â  Â  Â  Â  Â  radius: (data) => DrawingUtils.lerp(data.from!.z, -0.15, 0.1, 5, 1),
Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  Â  uploadDrawingUtils.drawConnectors(
Â  Â  Â  Â  Â  Â  Â  Â  scaledLandmarks,
Â  Â  Â  Â  Â  Â  Â  Â  PoseLandmarker.POSE_CONNECTIONS
Â  Â  Â  Â  Â  Â  Â  );
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });
Â  Â  Â  } catch (error) {
Â  Â  Â  Â  console.error("Detection error:", error);
Â  Â  Â  Â  uploadVideoPredicting = false;
Â  Â  Â  }
Â  Â  }

Â  Â  if (uploadVideoPredicting && !uploadedVideo.paused && !uploadedVideo.ended) {
Â  Â  Â  requestAnimationFrame(predictUploadedVideo);
Â  Â  } else {
Â  Â  Â  uploadVideoPredicting = false;
Â  Â  }
Â  }
}
